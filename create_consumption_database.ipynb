{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ Part 1 ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import os\n",
    "import re\n",
    "import brightway2 as bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments to the following code\n",
    "> - ### Raw data: Excel sheet can be obtained from https://doi.org/10.1021/acs.est.8b01452\n",
    "> - ### Terms `exchange` and `input activity` are used interchangeably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still TODO\n",
    "> - ### First exchange should be in 1 unit - probably not the case for us -> check that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database name\n",
    "CONSUMPTION_DB_NAME = 'CH consumption 1.0'\n",
    "# Number of relevant columns in the raw file (df_raw) to extract info about activity\n",
    "N_ACT_RELEVANT = 11\n",
    "# Index of the column where activities start\n",
    "FIRST_ACT_IND = 7\n",
    "# Number of columns that contain info about one activity\n",
    "N_COLUMNS_INPUT_ACTIVITY = 5\n",
    "\n",
    "# Column names for exchanges needed by brightway\n",
    "EXC_COLUMNS_DICT = {\n",
    "        'name': 'A', \n",
    "        'reference product': 'B', \n",
    "        'location': 'C', \n",
    "        'amount': 'D', \n",
    "        'unit': 'E', \n",
    "        'database': 'F', \n",
    "        'type': 'G', \n",
    "        'categories': 'H',\n",
    "        'comment': 'I',\n",
    "    }\n",
    "\n",
    "# Conversion from type in databases to type that should be in excel file to import a new database\n",
    "ACTIVITY_TYPE_DICT = {\n",
    "    'process': 'technosphere',\n",
    "    'emission': 'biosphere',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to brightway database format -> all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing On columns\n",
    "def complete_columns(df):\n",
    "    \n",
    "    column_names = list(df.columns)\n",
    "    indices = [i for i,el in enumerate(column_names)  if 'Activity' in el]\n",
    "    column_names_complete = copy(column_names)\n",
    "\n",
    "    n_el_added = 0\n",
    "    for ind in indices:\n",
    "        if 'On' not in column_names[ind-1]:\n",
    "            act_name = column_names[ind]\n",
    "            act_number = act_name[act_name.find(' ')+1:]\n",
    "            column_names_complete.insert(ind+n_el_added, 'On ' + act_number)\n",
    "            n_el_added += 1\n",
    "        \n",
    "    df.columns = column_names_complete[:len(column_names)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_bw(db_name, n_cutoff_cols = len(EXC_COLUMNS_DICT)+3):\n",
    "    '''\n",
    "    Create dataframe for a new database in the Brightway format and add the necessary meta information\n",
    "    '''\n",
    "    df = pd.DataFrame([['cutoff', n_cutoff_cols], ['database', db_name]], columns=list('AB'))\n",
    "    df = df.append(pd.Series(), ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_act_unit(df):\n",
    "    '''\n",
    "    Depending on whether `Quantity code` is present for a specific activity, \n",
    "    set unit to the unit of the first input activity or CHF.\n",
    "    '''\n",
    "    if 'Quantity code' in df.keys():\n",
    "        return df['DB Act 1'].split('(')[1].split(',')[0]\n",
    "    else:\n",
    "        return 'CHF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_activity(df, df_ind):\n",
    "    '''\n",
    "    Append activity from row df_ind to the dataframe df in the brightway format\n",
    "    '''\n",
    "    # Append empty row\n",
    "    df = df.append(pd.Series(), ignore_index=True)\n",
    "    \n",
    "    # Extract activity information\n",
    "    act_name = df_ind['Translated name']\n",
    "    act_unit = compute_act_unit(df)\n",
    "    \n",
    "    len_df = len(df)\n",
    "    \n",
    "    act_data = [ ['Activity', act_name],\n",
    "                 ['reference product',  act_name],\n",
    "                 ['location', 'CH'],\n",
    "                 ['amount', 1],\n",
    "                 ['unit', act_unit] ]\n",
    "    \n",
    "    df_act = pd.DataFrame( act_data, \n",
    "                           columns=list('AB'),\n",
    "                           index = np.arange(len_df,len_df+len(act_data)) )\n",
    "                          \n",
    "    df = df.append(df_act, sort=False)\n",
    "    \n",
    "    return df, df_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_exchanges_in_correct_columns(df, dict_with_values):\n",
    "    '''\n",
    "    Make sure that exchanges values are appended to df in the correct columns.\n",
    "    '''  \n",
    "    col_names = list(dict_with_values.keys()) # order of columns is determined by this list\n",
    "    col_excel_literal = [EXC_COLUMNS_DICT[m] for m in col_names]\n",
    "    \n",
    "    if dict_with_values != EXC_COLUMNS_DICT:\n",
    "        col_data  = [dict_with_values[m] for m in col_names]\n",
    "    else:\n",
    "        col_data = col_names\n",
    "    \n",
    "    df = df.append(pd.DataFrame([col_data], columns=col_excel_literal, index=[len(df)]), sort=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_exchanges_column_names(df):\n",
    "    '''\n",
    "    Add column names for exchanges\n",
    "    '''\n",
    "    df = df.append(pd.DataFrame(['Exchanges'], columns=['A'], index=[len(df)]), sort=False)\n",
    "    df = append_exchanges_in_correct_columns(df, EXC_COLUMNS_DICT)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_first_exchange(df, df_act):\n",
    "    '''\n",
    "    Append first exchange which is activity itself, the amount is always 1, \n",
    "    the database is always the one that is being currently created, type is `production`.\n",
    "    '''\n",
    "    df_act_dict = df_act.set_index('A').to_dict()['B']\n",
    "    \n",
    "    first_exc_data_dict = { 'name': df_act_dict['Activity'],\n",
    "                            'reference product': df_act_dict['reference product'],\n",
    "                            'location': df_act_dict['location'],\n",
    "                            'amount': 1,\n",
    "                            'unit': df_act_dict['unit'],\n",
    "                            'database': CONSUMPTION_DB_NAME,\n",
    "                            'type': 'production',\n",
    "                          }\n",
    "    \n",
    "    df = append_exchanges_in_correct_columns(df, first_exc_data_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pattern_correct(df_ind_j):\n",
    "    '''\n",
    "    Check that input activity info has correct pattern. \n",
    "    In case the pattern is not correct, move on to the next 5 columns and check their pattern.\n",
    "    This is needed because for some input activities some relevant values are missing, eg only 'On' value is present.\n",
    "    '''\n",
    "    list_ = list(df_ind_j.index)\n",
    "    pattern = ['On', 'Activity', 'DB Act', 'CFL Act', 'Amount Act']\n",
    "    check = [pattern[n] in list_[n] for n in range(N_COLUMNS_INPUT_ACTIVITY)]\n",
    "    if np.all(check): \n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_exchanges(df, df_ind, df_act):\n",
    "    '''\n",
    "    Add all exchanges (input activities) from the row df_ind to consumption database dataframe.\n",
    "    '''\n",
    "    # Add exchanges column names\n",
    "    df = append_exchanges_column_names(df)\n",
    "    \n",
    "    # Add first exchange that is the same as the activity itself, type of this exchange is production\n",
    "    df = append_first_exchange(df, df_act)\n",
    "    \n",
    "    # Add all exchanges\n",
    "    n_exchanges = (len(df_ind)-FIRST_ACT_IND) // N_COLUMNS_INPUT_ACTIVITY\n",
    "    if n_exchanges != (len(df_ind) - FIRST_ACT_IND) / N_COLUMNS_INPUT_ACTIVITY:\n",
    "        print('smth is not right with exchanges of Activity -> ' + str(df_ind['Translated name']))\n",
    "    \n",
    "    ConversionDem2FU = df_ind['ConversionDem2FU']\n",
    "    skip = 0\n",
    "    for j in range(1, n_exchanges+1):\n",
    "        \n",
    "        start = FIRST_ACT_IND + N_COLUMNS_INPUT_ACTIVITY*(j-1) + skip\n",
    "        end = start + N_COLUMNS_INPUT_ACTIVITY\n",
    "        df_ind_j = df_ind[start:end]\n",
    "        \n",
    "        #Check that df_ind_j contains <On 1, Activity 1, DB Act 1, CFL Act 1, Amount Act 1> pattern\n",
    "        flag = 1\n",
    "        while flag:\n",
    "            flag_pattern = is_pattern_correct(df_ind_j) \n",
    "            if flag_pattern == 1: # we don't need to skip if patter is correct\n",
    "                flag = 0\n",
    "            else:\n",
    "                skip += 1\n",
    "                start = FIRST_ACT_IND + N_COLUMNS_INPUT_ACTIVITY*(j-1) + skip\n",
    "                end = start + N_COLUMNS_INPUT_ACTIVITY\n",
    "                df_ind_j = df_ind[start:end]\n",
    "        \n",
    "        df = append_one_exchange(df, df_ind_j, ConversionDem2FU)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_act_dict(act_bw, input_act_amount):\n",
    "    '''\n",
    "    Create a dictionary with all info about input activities.\n",
    "    '''\n",
    "    \n",
    "    input_act_values_dict = {\n",
    "        'name': act_bw['name'], \n",
    "        'location': act_bw['location'], \n",
    "        'amount': input_act_amount, \n",
    "        'unit': act_bw['unit'], \n",
    "        'database': act_bw['database'], \n",
    "        # We do not expect type biosphere, but assign it via ACTIVITY_TYPE_DICT anyway \n",
    "        # to be sure that we don't encounter them.\n",
    "        'type': ACTIVITY_TYPE_DICT[act_bw['type']],\n",
    "    }\n",
    "    try:\n",
    "        input_act_values_dict['reference product'] = act_bw['reference product']\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    return input_act_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bw_get_activity_info_manually(input_act_str, db_name, input_act_amount):\n",
    "    # Extract the activity name\n",
    "    apostrophes = [(m.start(0), m.end(0)) for m in re.finditer(\"'\", input_act_str)]\n",
    "    if len(apostrophes) == 1:\n",
    "        ap_start = 0\n",
    "        ap_end = apostrophes[0][0]\n",
    "    else:\n",
    "        ap_start = apostrophes[0][1]\n",
    "        ap_end = apostrophes[1][0]\n",
    "    input_act_name = input_act_str[ ap_start:ap_end ]\n",
    "    input_act_unit_loc = input_act_str[ input_act_str.find(\"(\") : input_act_str.find(\")\")+1 ]\n",
    "    input_act_unit_loc_split = [ re.sub('[^-A-Za-z0-9-€-]', ' ' , el).rstrip().lstrip() \\\n",
    "                                 for el in input_act_unit_loc.split(',')]\n",
    "    input_act_unit = input_act_unit_loc_split[0]\n",
    "    input_act_location = input_act_unit_loc_split[1]\n",
    "\n",
    "    # Add comment when activity cannot be found\n",
    "    input_act_values_dict = {}\n",
    "    input_act_values_dict['name'] = input_act_name\n",
    "    input_act_values_dict['unit'] = input_act_unit\n",
    "    input_act_values_dict['location'] = input_act_location\n",
    "    input_act_values_dict['amount'] = input_act_amount\n",
    "    input_act_values_dict['database'] = db_name\n",
    "    input_act_values_dict['type'] = ACTIVITY_TYPE_DICT['process'] # TODO remove hardcoding\n",
    "    input_act_values_dict['comment'] = 'TODO could not find this activity'\n",
    "\n",
    "    return input_act_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " def append_one_exchange(df, df_ind_j, ConversionDem2FU):\n",
    "    '''\n",
    "    Extract information about one input activity, eg name, unit, location, etc and append it to the dataframe df.\n",
    "    '''    \n",
    "    # Extract the activity number\n",
    "    k = int(''.join(c for c in df_ind_j.index[0] if c.isdigit()))\n",
    "    # Extract information about activity and save it\n",
    "    input_act_str = df_ind_j['DB Act ' + str(k)]\n",
    "    input_act_db_code = df_ind_j['Activity ' + str(k)]\n",
    "    \n",
    "    # Find this input activity in brightway databases\n",
    "    db_name = input_act_db_code.split(\"'\")[1]\n",
    "    code = input_act_db_code.split(\"'\")[3]\n",
    "    input_act_db_code_tuple = (db_name, code)\n",
    "    \n",
    "    # TODO remove HEIA for now\n",
    "    if 'heia' in db_name:\n",
    "        return df\n",
    "    \n",
    "    # Compute amount\n",
    "    input_act_amount = ConversionDem2FU \\\n",
    "                     * df_ind_j['On ' + str(k)] \\\n",
    "                     * df_ind_j['CFL Act ' + str(k)] \\\n",
    "                     * df_ind_j['Amount Act ' + str(k)]\n",
    "    \n",
    "    try:\n",
    "        # Find activity using bw functionality\n",
    "        act_bw = bw.get_activity(input_act_db_code_tuple)\n",
    "        input_act_values_dict = create_input_act_dict(act_bw, input_act_amount)\n",
    "    except:\n",
    "        # If bw.get_activity does not work for whichever reason, fill info manually\n",
    "        input_act_values_dict = bw_get_activity_info_manually(input_act_str, db_name, input_act_amount)\n",
    "        \n",
    "    # Add exchange to the dataframe with database in brightway format\n",
    "    df = append_exchanges_in_correct_columns(df, input_act_values_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def append_one_exchange_old(df, df_ind_j, ConversionDem2FU):\n",
    "#     '''\n",
    "#     Extract information about one input activity, eg name, unit, location, etc and append it to the dataframe df.\n",
    "#     '''    \n",
    "#     # Extract the activity number\n",
    "#     k = int(''.join(c for c in df_ind_j.index[0] if c.isdigit()))\n",
    "    \n",
    "#     input_act_str = df_ind['DB Act ' + str(k)]\n",
    "    \n",
    "#     # Extract the activity name\n",
    "#     apostrophes = [(m.start(0), m.end(0)) for m in re.finditer(\"'\", input_act_str)]\n",
    "#     if len(apostrophes) == 1:\n",
    "#         ap_start = 0\n",
    "#         ap_end = apostrophes[0][0]\n",
    "#     else:\n",
    "#         ap_start = apostrophes[0][1]\n",
    "#         ap_end = apostrophes[1][0]\n",
    "#     input_act_name = input_act_str[ ap_start:ap_end ]\n",
    "    \n",
    "#     input_act_unit_loc = input_act_str[ input_act_str.find(\"(\") : input_act_str.find(\")\")+1 ]\n",
    "# #     input_act_unit_loc_split = [ re.sub('\\W+', ' ' , el) for el in input_act_unit_loc.split(',')]\n",
    "#     input_act_unit_loc_split = [ re.sub('[^-A-Za-z0-9-€-]', ' ' , el).rstrip().lstrip() \\\n",
    "#                                  for el in input_act_unit_loc.split(',')]\n",
    "#     input_act_unit = input_act_unit_loc_split[0]\n",
    "#     input_act_location = input_act_unit_loc_split[1]\n",
    "    \n",
    "#     # Extract input activity amount\n",
    "#     input_act_amount = df_ind['On ' + str(k)] * df_ind['CFL Act ' + str(k)] * df_ind['Amount Act ' + str(k)]\n",
    "    \n",
    "#     # Find this input activity in brightway databases\n",
    "#     input_act_db_code = df_ind['Activity ' + str(k)]\n",
    "#     db_name = input_act_db_code.split(\"'\")[1]\n",
    "#     db = bw.Database(db_name)\n",
    "    \n",
    "#     # TODO remove HEIA for now\n",
    "#     if 'heia' in db_name:\n",
    "#         return df\n",
    "    \n",
    "#     if 'EXIOBASE' in db_name and input_act_location == 'CH':\n",
    "#         input_act_location = 'Switzerland'\n",
    "    \n",
    "#     acts_bw = [act for act in db if  input_act_name == act['name'] \\\n",
    "#                                  and input_act_unit == act['unit'] \\\n",
    "#                                  and input_act_location == act['location']]\n",
    "    \n",
    "#     # TODO change this part once we get rid of non unique activities\n",
    "#     try:\n",
    "#         act_bw = acts_bw[0]   \n",
    "#         input_act_values_dict = create_input_act_dict(act_bw, input_act_amount)\n",
    "        \n",
    "#         # Add comment when activity is not unique\n",
    "#         if len(acts_bw) > 1:\n",
    "#             input_act_values_dict['comment'] = 'TODO: not unique!'\n",
    "            \n",
    "#     except:\n",
    "#         # Add comment when activity cannot be found\n",
    "#         input_act_values_dict = {}\n",
    "#         input_act_values_dict['name'] = input_act_name\n",
    "#         input_act_values_dict['unit'] = input_act_unit\n",
    "#         input_act_values_dict['location'] = input_act_location\n",
    "#         input_act_values_dict['amount'] = input_act_amount\n",
    "#         input_act_values_dict['database'] = db_name\n",
    "#         input_act_values_dict['type'] = ACTIVITY_TYPE_DICT['process'] # TODO remove hardcoding\n",
    "#         input_act_values_dict['comment'] = 'TODO: cannot find this activity'\n",
    "        \n",
    "#     # Add exchange to the dataframe with database in brightway format\n",
    "#     df = append_exchanges_in_correct_columns(df, input_act_values_dict)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to brightway database format -> main code\n",
    "calls all the functions used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smth is not right with exchanges of Activity -> Desktop computers\n",
      "smth is not right with exchanges of Activity -> Rice\n",
      "smth is not right with exchanges of Activity -> Pasta products\n",
      "smth is not right with exchanges of Activity -> Bread  \n",
      "smth is not right with exchanges of Activity -> Wheat flour \n",
      "smth is not right with exchanges of Activity -> Other flours and meals, starches, semolina, flakes and grains\n",
      "smth is not right with exchanges of Activity -> Other cereal products\n",
      "smth is not right with exchanges of Activity -> Beef\n",
      "smth is not right with exchanges of Activity -> Veal\n",
      "smth is not right with exchanges of Activity -> Pork, fresh or frozen\n",
      "smth is not right with exchanges of Activity -> Horse meat\n",
      "smth is not right with exchanges of Activity -> Sheep and Goat meat\n",
      "smth is not right with exchanges of Activity -> Poultry, fresh or frozen\n",
      "smth is not right with exchanges of Activity -> Hare, game and rabbit meat\n",
      "smth is not right with exchanges of Activity -> Other eatable meat products incl. offal, fresh and frozen\n",
      "smth is not right with exchanges of Activity -> Sausages, cold meat and pies\n",
      "smth is not right with exchanges of Activity -> Ham, bacon and other cured or smoked pork\n",
      "smth is not right with exchanges of Activity -> Poultry, grilled or smoked\n",
      "smth is not right with exchanges of Activity -> Other boiled, dried, cured or smoked meat\n",
      "smth is not right with exchanges of Activity -> Tinned meat and other meat-based preparations\n",
      "smth is not right with exchanges of Activity -> Fish\n",
      "smth is not right with exchanges of Activity -> Whole milk\n",
      "smth is not right with exchanges of Activity -> Skimmed and low-fat milk\n",
      "smth is not right with exchanges of Activity -> Hard and semi-hard cheese\n",
      "smth is not right with exchanges of Activity -> Fresh, soft and melted cheese\n",
      "smth is not right with exchanges of Activity -> Cream\n",
      "smth is not right with exchanges of Activity -> Curd\n",
      "smth is not right with exchanges of Activity -> Yoghurt\n",
      "smth is not right with exchanges of Activity -> Milk-based beverages and other similar milk-based products\n",
      "smth is not right with exchanges of Activity -> Fresh eggs\n",
      "smth is not right with exchanges of Activity -> Processed eggs\n",
      "smth is not right with exchanges of Activity -> Butter\n",
      "smth is not right with exchanges of Activity -> Margarine\n",
      "smth is not right with exchanges of Activity -> Other vegetable fats\n",
      "smth is not right with exchanges of Activity -> Olive oil\n",
      "smth is not right with exchanges of Activity -> Other vegetable oils and edible animal fats\n",
      "smth is not right with exchanges of Activity -> Lemons\n",
      "smth is not right with exchanges of Activity -> Oranges and other citrus fruits\n",
      "smth is not right with exchanges of Activity -> Banana\n",
      "smth is not right with exchanges of Activity -> Apples\n",
      "smth is not right with exchanges of Activity -> Pears and quinces\n",
      "smth is not right with exchanges of Activity -> Stone fruit\n",
      "smth is not right with exchanges of Activity -> Berries\n",
      "smth is not right with exchanges of Activity -> Grapes\n",
      "smth is not right with exchanges of Activity -> Melons and watermelons\n",
      "smth is not right with exchanges of Activity -> Other tropical fruits\n",
      "smth is not right with exchanges of Activity -> Nuts, other edible nuts and seeds oleaginous fruits\n",
      "smth is not right with exchanges of Activity -> Other fried fruits\n",
      "smth is not right with exchanges of Activity -> Preserved fruits\n",
      "smth is not right with exchanges of Activity -> Green salads and other leafy vegetables\n",
      "smth is not right with exchanges of Activity -> Stem vegetables\n",
      "smth is not right with exchanges of Activity -> Brassicas\n",
      "smth is not right with exchanges of Activity -> Tomatoes\n",
      "smth is not right with exchanges of Activity -> Beans and peas\n",
      "smth is not right with exchanges of Activity -> Other fruiting vegetables\n",
      "smth is not right with exchanges of Activity -> Onions\n",
      "smth is not right with exchanges of Activity -> Garlic\n",
      "smth is not right with exchanges of Activity -> Beets and other root vegetables\n",
      "smth is not right with exchanges of Activity -> Mushrooms and vegetables, dried\n",
      "smth is not right with exchanges of Activity -> Tinned or processed vegetables and mushrooms\n",
      "smth is not right with exchanges of Activity -> Potatoes \n",
      "smth is not right with exchanges of Activity -> Potatoes-based products and other tuber vegetables\n",
      "smth is not right with exchanges of Activity -> Sugar  \n",
      "smth is not right with exchanges of Activity -> Jams, marmalades, compotes\n",
      "smth is not right with exchanges of Activity -> Honey\n",
      "smth is not right with exchanges of Activity -> Chocolate\n",
      "smth is not right with exchanges of Activity -> Sweets and chewing gum\n",
      "smth is not right with exchanges of Activity -> Ice cream\n",
      "smth is not right with exchanges of Activity -> Pure and ground coffee\n",
      "smth is not right with exchanges of Activity -> Instant coffee and coffee surrogates\n",
      "smth is not right with exchanges of Activity -> Tea, herbal tea and surrogates\n",
      "smth is not right with exchanges of Activity -> Cocoa-based beverages\n",
      "smth is not right with exchanges of Activity -> Mineral water  \n",
      "smth is not right with exchanges of Activity -> Non-alcoholic soft drinks\n",
      "smth is not right with exchanges of Activity -> Syrups\n",
      "smth is not right with exchanges of Activity -> Fruit juices\n",
      "smth is not right with exchanges of Activity -> Vegetable juices\n",
      "smth is not right with exchanges of Activity -> Spirits\n",
      "smth is not right with exchanges of Activity -> Alcoholic and non-alcoholic liqueurs and liqueur-based aperitifs\n",
      "smth is not right with exchanges of Activity -> Wine\n",
      "smth is not right with exchanges of Activity -> Alcoholic and non-alcoholic beer\n",
      "smth is not right with exchanges of Activity -> Refuse collection costs at principal residence\n",
      "smth is not right with exchanges of Activity -> Wastewater collection fees of principal residence\n",
      "smth is not right with exchanges of Activity -> Water supply fees of principal residence\n",
      "smth is not right with exchanges of Activity -> Electricity of principal residence\n",
      "smth is not right with exchanges of Activity -> Natural gas and other fuels of principal residence\n",
      "smth is not right with exchanges of Activity -> Central heating or district heating of principal residence\n",
      "smth is not right with exchanges of Activity -> Gasoline\n",
      "smth is not right with exchanges of Activity -> Diesel\n",
      "CPU times: user 27.6 s, sys: 255 ms, total: 27.8 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Start brightway project that already contains databases\n",
    "project = 'GSA for ecoinvent'\n",
    "bw.projects.set_current(project)\n",
    "\n",
    "# Create dataframe that will be our consumption database after we add activities and exchanges from the raw file\n",
    "df_bw = create_df_bw(CONSUMPTION_DB_NAME)\n",
    "\n",
    "# Read data\n",
    "path = 'data/es8b01452_si_002.xlsx'\n",
    "sheet_name = 'Overview & LCA-Modeling'\n",
    "df_raw = pd.read_excel(path, sheet_name = sheet_name, header=2)\n",
    "\n",
    "# Add ON columns\n",
    "df = complete_columns(df_raw)\n",
    "\n",
    "act_indices = df_raw.index[df_raw['ConversionDem2FU'].notna()].tolist() # indices of all activities\n",
    "\n",
    "for ind in act_indices:\n",
    "    # For each row\n",
    "    df_ind = df_raw.iloc[ind]\n",
    "    df_ind = df_ind[df_ind.notna()]\n",
    "    # Add activity\n",
    "    df_bw, df_act = append_activity(df_bw, df_ind[:N_ACT_RELEVANT]) # only pass columns relevant to this function \n",
    "    # Add exchanges\n",
    "    df_bw = append_exchanges(df_bw, df_ind, df_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframe to excel file\n",
    "write_dir_name = 'write_files'\n",
    "if not os.path.exists(write_dir_name):\n",
    "    os.mkdir(write_dir_name)\n",
    "db_bw_path = write_dir_name + '/' + 'consumption_db.xlsx'\n",
    "df_bw.to_excel(db_bw_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ Part 2 ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import brightway2 as bw\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_COLUMN = 'F'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace names of old databases with the new ones in the consumption database excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_one_db(df, db_old_name, db_new_name):\n",
    "    '''\n",
    "    Replace database name with a new one (eg in case a newer version is available)\n",
    "    '''\n",
    "    df_updated = copy(df)\n",
    "    \n",
    "    where = np.where(df_updated[DB_COLUMN]==db_old_name)[0]\n",
    "    if where.shape[0] != 0:\n",
    "        df_updated[DB_COLUMN][where] = db_new_name\n",
    "        \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all_db(df):\n",
    "    '''\n",
    "    Update all databases in the consumption database\n",
    "    '''\n",
    "    db_old_list = ['Agribalyse 1.2', \n",
    "                   'ecoinvent 3.3 cutoff']\n",
    "    db_new_list = ['Agribalyse 1.2 - ecoinvent 3.3 cutoff',\n",
    "                  'ecoinvent 3.6 cutoff']\n",
    "    \n",
    "    assert len(db_old_list) == len(db_new_list)\n",
    "    \n",
    "    for i in range(len(db_old_list)):\n",
    "        df = replace_one_db(df, db_old_list[i], db_new_list[i])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "project = 'GSA for ecoinvent'\n",
    "bw.projects.set_current(project)\n",
    "\n",
    "# Read consumption database\n",
    "path = 'write_files/consumption_db.xlsx'\n",
    "df = pd.read_excel(path, header = None)\n",
    "df.columns = list(string.ascii_uppercase[:len(df.columns)])\n",
    "# \n",
    "# Replace\n",
    "df = update_all_db(df)\n",
    "path_new_db = 'write_files/consumption_db_updated.xlsx'\n",
    "df.to_excel(path_new_db, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import consumption database linked to older versions of other databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ecoinvent 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Chris -> please check migrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1 worksheets in 0.41 seconds\n",
      "Applying strategy: csv_restore_tuples\n",
      "Applying strategy: csv_restore_booleans\n",
      "Applying strategy: csv_numerize\n",
      "Applying strategy: csv_drop_unknown\n",
      "Applying strategy: csv_add_missing_exchanges_section\n",
      "Applying strategy: normalize_units\n",
      "Applying strategy: normalize_biosphere_categories\n",
      "Applying strategy: normalize_biosphere_names\n",
      "Applying strategy: strip_biosphere_exc_locations\n",
      "Applying strategy: set_code_by_activity_hash\n",
      "Applying strategy: link_iterable_by_fields\n",
      "Applying strategy: assign_only_product_as_production\n",
      "Applying strategy: link_technosphere_by_activity_hash\n",
      "Applying strategy: drop_falsey_uncertainty_fields_but_keep_zeros\n",
      "Applying strategy: convert_uncertainty_types_to_integers\n",
      "Applying strategy: convert_activity_parameters_to_list\n",
      "Applied 16 strategies in 0.31 seconds\n",
      "Applying strategy: link_iterable_by_fields\n",
      "Applying strategy: link_iterable_by_fields\n",
      "Applying strategy: link_iterable_by_fields\n",
      "203 datasets\n",
      "6058 exchanges\n",
      "95 unlinked exchanges\n",
      "  Type technosphere: 11 unique unlinked exchanges\n"
     ]
    }
   ],
   "source": [
    "if CONSUMPTION_DB_NAME in bw.databases:\n",
    "    print(CONSUMPTION_DB_NAME + \" database already present!!! No import is needed\")\n",
    "else: \n",
    "    co = bw.ExcelImporter(path_new_db)\n",
    "    co.apply_strategies()\n",
    "    co.match_database('EXIOBASE 2.2', fields=('name','reference product', 'unit','location','categories'))\n",
    "    co.match_database('ecoinvent 3.6 cutoff', fields=('name', 'reference product', 'unit','location','categories'))\n",
    "    co.match_database('Agribalyse 1.2 - ecoinvent 3.3 cutoff', fields=('name','unit','location'))\n",
    "    co.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(co.unlinked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a migration for two particular activities that can only be hardcoded\n",
    "ecoinvent36_change_names_data = {\n",
    "    'fields': ['name', ],\n",
    "    'data': [\n",
    "        (\n",
    "            ['steam production in chemical industry'], \n",
    "            {\n",
    "                'name': 'steam production, in chemical industry',\n",
    "                'reference product': 'steam, in chemical industry',\n",
    "                'unit': 'kilogram',\n",
    "                'multiplier': 1/2.75, # see comment on this activity in ecoinvent\n",
    "            }\n",
    "        ),\n",
    "        (\n",
    "            ['market for green bell pepper'],\n",
    "            {\n",
    "                'name': 'market for bell pepper',\n",
    "                'reference product': 'bell pepper',\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    "}\n",
    "\n",
    "bw.Migration(\"ecoinvent36-change-names\").write(\n",
    "    ecoinvent36_change_names_data,\n",
    "    description=\"Change names of some activities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a migration for rice production and specific locations\n",
    "# These locations have only non-basmati rice production\n",
    "ecoinvent36_rice_production_data = {\n",
    "    'fields': ['name', 'location'],\n",
    "    'data': [\n",
    "        (\n",
    "            ['rice production', 'US'],\n",
    "            {\n",
    "                'name': 'rice production, non-basmati',\n",
    "                'reference product': 'rice, non-basmati'\n",
    "            }\n",
    "        ),\n",
    "        (\n",
    "            ['rice production', 'CN'],\n",
    "            {\n",
    "                'name': 'rice production, non-basmati',\n",
    "                'reference product': 'rice, non-basmati'\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    "}\n",
    "\n",
    "bw.Migration(\"ecoinvent36-rice-production\").write(\n",
    "    ecoinvent36_rice_production_data,\n",
    "    description=\"Change names of some activities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying strategy: migrate_datasets\n",
      "Applying strategy: migrate_exchanges\n",
      "Applying strategy: migrate_datasets\n",
      "Applying strategy: migrate_exchanges\n",
      "Applying strategy: link_iterable_by_fields\n",
      "203 datasets\n",
      "6058 exchanges\n",
      "26 unlinked exchanges\n",
      "  Type technosphere: 7 unique unlinked exchanges\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(203, 6058, 26)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.migrate('ecoinvent36-change-names')\n",
    "co.migrate(\"ecoinvent36-rice-production\")\n",
    "co.match_database('ecoinvent 3.6 cutoff', fields=('name','reference product', 'unit','location','categories'))\n",
    "co.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a migration with allocation based on the share in production volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unlinked_act(db2import, unlinked_exc):\n",
    "    acts = []\n",
    "    for act in db2import.data:\n",
    "        for exc in act['exchanges']:\n",
    "            if exc == unlinked_exc:\n",
    "                acts.append(act)\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlinked_excs = list(co.unlinked)\n",
    "acts = [dict()]*len(unlinked_excs) # activities where the unlinked exchange is present\n",
    "i = 0\n",
    "for unlinked_exc in unlinked_excs:\n",
    "    acts[i][tuple(unlinked_exc)] = get_unlinked_act(co, unlinked_exc)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_activity() missing 1 required positional argument: 'ws'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-b8c66d971724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'database'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_activity() missing 1 required positional argument: 'ws'"
     ]
    }
   ],
   "source": [
    "co.get_activity((co.data[0]['database'], co.data[0]['code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_activities() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-313-f3bfe78fb118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_activities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: process_activities() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "co."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'market for rice',\n",
       " 'reference product': 'rice',\n",
       " 'location': 'GLO',\n",
       " 'amount': 0.0,\n",
       " 'unit': 'kilogram',\n",
       " 'database': 'ecoinvent 3.6 cutoff',\n",
       " 'type': 'technosphere'}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlinked_exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-e23a8d56ccb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlinked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/gsa-ei/lib/python3.7/site-packages/bw2io/importers/base.py\u001b[0m in \u001b[0;36munlinked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m         Uniqueness is determined by ``activity_hash``.\"\"\"\n\u001b[1;32m     85\u001b[0m         \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exchanges'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    next(co.unlinked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Desktop computers',\n",
       "  'reference product': 'Desktop computers',\n",
       "  'location': 'CH',\n",
       "  'amount': 1.0,\n",
       "  'unit': 'CHF',\n",
       "  'database': 'CH consumption 1.0',\n",
       "  'type': 'production',\n",
       "  'input': ('CH consumption 1.0', '13ee003610534e860db3cc78c1347cc1')},\n",
       " {'name': 'market for computer, desktop, without screen',\n",
       "  'reference product': 'computer, desktop, without screen',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.25,\n",
       "  'unit': 'unit',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere',\n",
       "  'input': ('ecoinvent 3.6 cutoff', '3fc8677e12987ef34d5dc084d6923c8f')},\n",
       " {'name': 'market for display, liquid crystal, 17 inches',\n",
       "  'reference product': 'display, liquid crystal, 17 inches',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.08333333333333333,\n",
       "  'unit': 'unit',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere',\n",
       "  'input': ('ecoinvent 3.6 cutoff', '4be589ad2931fbdd511f99ab5f062395')},\n",
       " {'name': 'market for display, cathode ray tube, 17 inches',\n",
       "  'reference product': 'display, cathode ray tube, 17 inches',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.08333333333333333,\n",
       "  'unit': 'unit',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere',\n",
       "  'input': ('ecoinvent 3.6 cutoff', '43a58c444a5cc46da701474140ce1cd4')},\n",
       " {'name': 'market for keyboard',\n",
       "  'reference product': 'keyboard',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.25,\n",
       "  'unit': 'unit',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere',\n",
       "  'input': ('ecoinvent 3.6 cutoff', '86cbbc43d633d639e94d0ec377aaf010')},\n",
       " {'name': 'market for pointing device, optical mouse, with cable',\n",
       "  'reference product': 'pointing device, optical mouse, with cable',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.25,\n",
       "  'unit': 'unit',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere',\n",
       "  'input': ('ecoinvent 3.6 cutoff', 'c3840b9c8929615e98209b6f25d2779b')}]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.data[0]['exchanges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'market for rice',\n",
       "  'reference product': 'rice',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.0,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'rice production',\n",
       "  'reference product': 'rice',\n",
       "  'location': 'RoW',\n",
       "  'amount': 1.1793134592,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'rice production',\n",
       "  'reference product': 'rice',\n",
       "  'location': 'IN',\n",
       "  'amount': 0.1380030448211913,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for wheat grain',\n",
       "  'reference product': 'wheat grain',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.0,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for maize grain',\n",
       "  'reference product': 'maize grain',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.0,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for mandarin',\n",
       "  'reference product': 'mandarin',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.1078517397384,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for soybean',\n",
       "  'reference product': 'soybean',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.006341003536001146,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'}]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(co.unlinked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unlinked(co, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlinked exchange: market for rice, kilogram, GLO, rice\n",
      "'market for rice, non-basmati' (kilogram, GLO, None) - rice, non-basmati\n",
      "'market for rice, basmati' (kilogram, GLO, None) - rice, basmati\n",
      "'market for rice seed, for sowing' (kilogram, GLO, None) - rice seed, for sowing\n",
      "\n",
      "\n",
      "Unlinked exchange: rice production, kilogram, RoW, rice\n",
      "'rice production, basmati' (kilogram, RoW, None) - rice, basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - rice, non-basmati\n",
      "'rice production, basmati' (kilogram, IN, None) - rice, basmati\n",
      "'rice production, non-basmati' (kilogram, IN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - straw\n",
      "'rice production, non-basmati' (kilogram, US, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - straw\n",
      "\n",
      "\n",
      "Unlinked exchange: rice production, kilogram, US, rice\n",
      "'rice production, basmati' (kilogram, RoW, None) - rice, basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - straw\n",
      "'rice production, non-basmati' (kilogram, CN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, US, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - straw\n",
      "'rice production, non-basmati' (kilogram, IN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - rice, non-basmati\n",
      "'rice production, basmati' (kilogram, IN, None) - rice, basmati\n",
      "\n",
      "\n",
      "Unlinked exchange: rice production, kilogram, IN, rice\n",
      "'rice production, basmati' (kilogram, IN, None) - rice, basmati\n",
      "'rice production, basmati' (kilogram, RoW, None) - rice, basmati\n",
      "'rice production, non-basmati' (kilogram, US, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - straw\n",
      "'rice production, non-basmati' (kilogram, IN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - straw\n",
      "\n",
      "\n",
      "Unlinked exchange: rice production, kilogram, CN, rice\n",
      "'rice production, non-basmati' (kilogram, US, None) - rice, non-basmati\n",
      "'rice production, basmati' (kilogram, IN, None) - rice, basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - straw\n",
      "'rice production, basmati' (kilogram, RoW, None) - rice, basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, CN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, IN, None) - rice, non-basmati\n",
      "'rice production, non-basmati' (kilogram, RoW, None) - straw\n",
      "\n",
      "\n",
      "Unlinked exchange: market for wheat grain, kilogram, GLO, wheat grain\n",
      "'market for wheat grain' (kilogram, RoW, None) - wheat grain\n",
      "'market for wheat grain, feed, organic' (kilogram, GLO, None) - wheat grain, feed, organic\n",
      "'market for wheat grain, organic' (kilogram, GLO, None) - wheat grain, organic\n",
      "'market for wheat grain, Swiss integrated production' (kilogram, CH, None) - wheat grain, Swiss integrated production\n",
      "'market for wheat grain' (kilogram, ZA, None) - wheat grain\n",
      "'market for wheat grain, feed' (kilogram, GLO, None) - wheat grain, feed\n",
      "'market for wheat grain, feed, Swiss integrated production' (kilogram, CH, None) - wheat grain, feed, Swiss integrated production\n",
      "\n",
      "\n",
      "Unlinked exchange: market for maize grain, kilogram, GLO, maize grain\n",
      "'market for maize grain, feed, organic' (kilogram, GLO, None) - maize grain, feed, organic\n",
      "'market for maize grain, feed' (kilogram, RoW, None) - maize grain, feed\n",
      "'market for maize grain, feed' (kilogram, ZA, None) - maize grain, feed\n",
      "'market for maize grain, feed, Swiss integrated production' (kilogram, CH, None) - maize grain, feed, Swiss integrated production\n",
      "'market for maize grain, organic' (kilogram, GLO, None) - maize grain, organic\n",
      "'market for maize grain' (kilogram, ZA, None) - maize grain\n",
      "'market for maize grain' (kilogram, BR, None) - maize grain\n",
      "'market for maize grain, Swiss integrated production' (kilogram, GLO, None) - maize grain, Swiss integrated production\n",
      "'market for maize grain' (kilogram, RoW, None) - maize grain\n",
      "\n",
      "\n",
      "Unlinked exchange: market for mandarin, kilogram, GLO, mandarin\n",
      "'market for mandarin, fresh grade' (kilogram, GLO, None) - mandarin, fresh grade\n",
      "'market for mandarin' (kilogram, RoW, None) - mandarin\n",
      "'market for mandarin' (kilogram, ZA, None) - mandarin\n",
      "'market for mandarin, processing grade' (kilogram, GLO, None) - mandarin, processing grade\n",
      "\n",
      "\n",
      "Unlinked exchange: market for soybean, kilogram, GLO, soybean\n",
      "'market for soybean oil, crude' (kilogram, GLO, None) - soybean oil, crude\n",
      "'market for soybean' (kilogram, RoW, None) - soybean\n",
      "'market for soybean, organic' (kilogram, GLO, None) - soybean, organic\n",
      "'market for soybean' (kilogram, BR, None) - soybean\n",
      "'market for soybean meal' (kilogram, BR, None) - soybean meal\n",
      "'market for soybean meal' (kilogram, RoW, None) - soybean meal\n",
      "'market for soybean beverage' (litre, GLO, None) - soybean beverage\n",
      "'market for soybean, Swiss integrated production' (kilogram, CH, None) - soybean, Swiss integrated production\n",
      "'market for soybean, feed' (kilogram, GLO, None) - soybean, feed\n",
      "'market for soybean seed, for sowing' (kilogram, GLO, None) - soybean seed, for sowing\n",
      "'market for soybean oil, refined' (kilogram, GLO, None) - soybean oil, refined\n",
      "'market for soybean seed, organic, for sowing' (kilogram, GLO, None) - soybean seed, organic, for sowing\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for u in list(co.unlinked):\n",
    "    print('Unlinked exchange: ' + u['name'] + ', ' + \\\n",
    "                                  u['unit'] + ', ' + \\\n",
    "                                  u['location'] + ', ' + \\\n",
    "                                  u['reference product'])\n",
    "    [print(str(act) + ' - ' + act['reference product']) for act in db if u['name'] in act['name']]\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def split_exchange_by_production_volume(exc, data, total, lst):\n",
    "    for obj, amount in data:\n",
    "        new_exc = deepcopy(exc)\n",
    "        # Could also use rescale_exchange function from wurst here\n",
    "        new_exc[\"amount\"] *= value / total\n",
    "        # Create direct link to this particular dataset\n",
    "        new_exc[\"input\"] = (obj[\"database\"], obj[\"code\"])\n",
    "        lst.append(new_exc)\n",
    "    return new_exc\n",
    "\n",
    "def split_by_production_volume(data, search_db, old_exchange_properties, new_exchange_properties):\n",
    "    \"\"\"\n",
    "    Given some data being imported, `data`, and a database to search in, `search_db`, \n",
    "    take each exchange matching `old_exchange_properties`, and split it into multiple exchanges \n",
    "    matching `new_exchange_properties`, using production volumes as allocation factors.\n",
    "    \"\"\"\n",
    "    matched_datasets = [\n",
    "        ds\n",
    "        for ds in search_db\n",
    "        if all(ds[key] == value for key, value in new_exchange_properties.items())\n",
    "    ]\n",
    "\n",
    "    production_volumes = [\n",
    "        next(ds.production()).get(\"production volume\", 0) for ds in matched_datasets\n",
    "    ]\n",
    "    if len(production_volumes) == 1:\n",
    "        # Fix if only one possible and no production volume\n",
    "        production_volumes = [1]\n",
    "    elif not production_volumes:\n",
    "        raise ValueError(\"No matching datasets found\")\n",
    "\n",
    "    for ds in data:\n",
    "        indices_to_drop, new_exchanges = [], []\n",
    "        for i, exc in enumerate(ds.get(\"exchanges\", [])):\n",
    "            if all(exc[key] == value for key, value in old_exchange_properties.items()):\n",
    "                indices_to_drop.append(i)\n",
    "                new_exchanges = split_exchange_by_production_volume(\n",
    "                    exc,\n",
    "                    zip(matched_datasets, production_volumes),\n",
    "                    sum(production_volumes),\n",
    "                    new_exchanges,\n",
    "                )\n",
    "\n",
    "        if new_exchanges:\n",
    "            ds[\"exchanges\"] = [\n",
    "                exc\n",
    "                for i, exc in enumerate(ds.get(\"exchanges\", []))\n",
    "                if i not in indices_to_drop\n",
    "            ] + new_exchanges\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_exchange_properties = {\n",
    "    'name': 'market for rice, basmati',\n",
    "    'location': 'GLO'\n",
    "                          }\n",
    "old_exchange_properties = {\n",
    "    'name': 'market for rice',\n",
    "    'location': 'GLO'\n",
    "}\n",
    "\n",
    "matched_datasets = [act for act in db if all(act[key] == value for key, value in new_exchange_properties.items())]\n",
    "production_volumes = [\n",
    "        next(iter(ds.production())).get(\"production volume\", 0) for ds in matched_datasets\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12520000000.0]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'name': 'market for rice',\n",
    "  'reference product': 'rice',\n",
    "  'location': 'GLO',\n",
    "  'amount': 0.0,\n",
    "  'unit': 'kilogram',\n",
    "  'database': 'ecoinvent 3.6 cutoff',\n",
    "  'type': 'technosphere'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in data:\n",
    "    indices_to_drop, new_exchanges = [], []\n",
    "    for i, exc in enumerate(ds.get(\"exchanges\", [])):\n",
    "        if all(exc[key] == value for key, value in old_exchange_properties.items()):\n",
    "            indices_to_drop.append(i)\n",
    "            new_exchanges = split_exchange_by_production_volume(\n",
    "                exc,\n",
    "                zip(matched_datasets, production_volumes),\n",
    "                sum(production_volumes),\n",
    "                new_exchanges,\n",
    "            )\n",
    "\n",
    "    if new_exchanges:\n",
    "        ds[\"exchanges\"] = [\n",
    "            exc\n",
    "            for i, exc in enumerate(ds.get(\"exchanges\", []))\n",
    "            if i not in indices_to_drop\n",
    "        ] + new_exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comment': \"This dataset represents the supply of 1 kg of 'rice, basmati' from activities that produce it within the geography of GLO. Transportation is included in this market. The transport amounts are based on the default transport distances for markets, provided in the 'Default Transport Assumptions' file available on the ecoinvent website (https://www.ecoinvent.org/support/documents-and-files/documents-and-files.html). See exchange comments for additional details.\",\n",
       " 'classifications': [('ISIC rev.4 ecoinvent', '0112:Growing of rice'),\n",
       "  ('CPC', '0113: Rice')],\n",
       " 'activity type': 'market activity',\n",
       " 'activity': 'e3efbc2d-9334-4160-b16a-c68d13c9f2f2',\n",
       " 'database': 'ecoinvent 3.6 cutoff',\n",
       " 'filename': 'e3efbc2d-9334-4160-b16a-c68d13c9f2f2_f2711295-b251-4171-8316-516c3526b8ff.spold',\n",
       " 'location': 'GLO',\n",
       " 'name': 'market for rice, basmati',\n",
       " 'parameters': [],\n",
       " 'authors': {'data entry': {'name': '[System]',\n",
       "   'email': 'support@ecoinvent.org'},\n",
       "  'data generator': {'name': 'Avraam Symeonidis',\n",
       "   'email': 'Symeonidis@ecoinvent.org'}},\n",
       " 'type': 'process',\n",
       " 'reference product': 'rice, basmati',\n",
       " 'flow': 'f2711295-b251-4171-8316-516c3526b8ff',\n",
       " 'unit': 'kilogram',\n",
       " 'production amount': 1.0,\n",
       " 'code': '1a17e39261f37a262dd3d8a3c69f2f05'}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = matched_datasets[0]\n",
    "a.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flow': 'f2711295-b251-4171-8316-516c3526b8ff',\n",
       " 'type': 'production',\n",
       " 'name': 'rice, basmati',\n",
       " 'classifications': {'CPC': ['0113: Rice']},\n",
       " 'production volume': 12520000000.0,\n",
       " 'activity': 'e3efbc2d-9334-4160-b16a-c68d13c9f2f2',\n",
       " 'unit': 'kilogram',\n",
       " 'amount': 1.0,\n",
       " 'uncertainty type': 0,\n",
       " 'loc': 1.0,\n",
       " 'input': ('ecoinvent 3.6 cutoff', '1a17e39261f37a262dd3d8a3c69f2f05'),\n",
       " 'output': ('ecoinvent 3.6 cutoff', '1a17e39261f37a262dd3d8a3c69f2f05')}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(a.production()))._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.production??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rice production, non-basmati' (kilogram, US, None)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[act for act in db if 'rice production' in act['name'] and 'US' in act['location']][0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'market for rice',\n",
       "  'reference product': 'rice',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.0,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'rice production',\n",
       "  'reference product': 'rice',\n",
       "  'location': 'RoW',\n",
       "  'amount': 1.1793134592,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'rice production',\n",
       "  'reference product': 'rice',\n",
       "  'location': 'IN',\n",
       "  'amount': 0.1380030448211913,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for wheat grain',\n",
       "  'reference product': 'wheat grain',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.0,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for maize grain',\n",
       "  'reference product': 'maize grain',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.0,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for mandarin',\n",
       "  'reference product': 'mandarin',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.1078517397384,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'},\n",
       " {'name': 'market for soybean',\n",
       "  'reference product': 'soybean',\n",
       "  'location': 'GLO',\n",
       "  'amount': 0.006341003536001146,\n",
       "  'unit': 'kilogram',\n",
       "  'database': 'ecoinvent 3.6 cutoff',\n",
       "  'type': 'technosphere'}]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(co.unlinked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
