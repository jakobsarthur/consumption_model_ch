{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments to the following code\n",
    "> - #### Parts 1 and 2 can be run separately\n",
    "> - #### Raw data: Excel sheet can be obtained from https://doi.org/10.1021/acs.est.8b01452\n",
    "> - #### Terms `exchange` and `input activity` are used interchangeably"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ Part 1 ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import os\n",
    "import re\n",
    "import brightway2 as bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still TODO\n",
    "> - ### First exchange should be in 1 unit - probably not the case for us -> check that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database name\n",
    "CONSUMPTION_DB_NAME = 'CH consumption 1.0'\n",
    "# Number of relevant columns in the raw file (df_raw) to extract info about activity\n",
    "N_ACT_RELEVANT = 11\n",
    "# Index of the column where activities start\n",
    "FIRST_ACT_IND = 7\n",
    "# Number of columns that contain info about one activity\n",
    "N_COLUMNS_INPUT_ACTIVITY = 5\n",
    "\n",
    "# Column names for exchanges needed by brightway\n",
    "EXC_COLUMNS_DICT = {\n",
    "        'name': 'A', \n",
    "        'reference product': 'B', \n",
    "        'location': 'C', \n",
    "        'amount': 'D', \n",
    "        'unit': 'E', \n",
    "        'database': 'F', \n",
    "        'type': 'G', \n",
    "        'categories': 'H',\n",
    "        'comment': 'I',\n",
    "    }\n",
    "\n",
    "# Conversion from type in databases to type that should be in excel file to import a new database\n",
    "ACTIVITY_TYPE_DICT = {\n",
    "    'process': 'technosphere',\n",
    "    'emission': 'biosphere',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to brightway database format -> all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing On columns\n",
    "def complete_columns(df):\n",
    "    \n",
    "    column_names = list(df.columns)\n",
    "    indices = [i for i,el in enumerate(column_names)  if 'Activity' in el]\n",
    "    column_names_complete = copy(column_names)\n",
    "\n",
    "    n_el_added = 0\n",
    "    for ind in indices:\n",
    "        if 'On' not in column_names[ind-1]:\n",
    "            act_name = column_names[ind]\n",
    "            act_number = act_name[act_name.find(' ')+1:]\n",
    "            column_names_complete.insert(ind+n_el_added, 'On ' + act_number)\n",
    "            n_el_added += 1\n",
    "        \n",
    "    df.columns = column_names_complete[:len(column_names)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_bw(db_name, n_cutoff_cols = len(EXC_COLUMNS_DICT)+3):\n",
    "    '''\n",
    "    Create dataframe for a new database in the Brightway format and add the necessary meta information\n",
    "    '''\n",
    "    df = pd.DataFrame([['cutoff', n_cutoff_cols], ['database', db_name]], columns=list('AB'))\n",
    "    df = df.append(pd.Series(), ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_act_unit(df):\n",
    "    '''\n",
    "    Depending on whether `Quantity code` is present for a specific activity, \n",
    "    set unit to the unit of the first input activity or CHF.\n",
    "    Comments on units from Andi for all codes that start with `mx`:\n",
    "        - kWh per year for electricity\n",
    "        - MJ per year for heating\n",
    "        - cubic meters per year for water supply and wastewater collection\n",
    "        - number of waste bags per year for refuse collection\n",
    "        --> we gonna hardcode them ;)\n",
    "        --> # TODO important Andi's model (total demands excel file) gives per year, but we divide by 12 later on\n",
    "    '''\n",
    "    \n",
    "    if 'Quantity code' in df.keys():\n",
    "        name = df['Translated name'].lower()\n",
    "        if 'electricity' in name:\n",
    "            return 'kilowatt hour'\n",
    "        elif 'heating' in name:\n",
    "            return 'megajoule'\n",
    "        elif 'water supply' in name:\n",
    "            return 'cubic meter'\n",
    "        elif 'wastewater collection' in name:\n",
    "            return 'cubic meter'\n",
    "        elif 'refuse collection' in name:\n",
    "            return \"number of waste bags\" \n",
    "    else:\n",
    "        try:    \n",
    "            return df['DB Act 1'].split('(')[1].split(',')[0]\n",
    "        except:\n",
    "            return 'TODO check'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_activity(df, df_ind):\n",
    "    '''\n",
    "    Append activity from row df_ind to the dataframe df in the brightway format\n",
    "    '''\n",
    "    # Append empty row\n",
    "    df = df.append(pd.Series(), ignore_index=True)\n",
    "    \n",
    "    # Extract activity information\n",
    "    act_name = df_ind['Translated name']\n",
    "    if 'Quantity code' in df_ind.index:\n",
    "        act_code = df_ind['Quantity code']\n",
    "    else:\n",
    "        act_code = df_ind['Variable code']\n",
    "    act_unit = compute_act_unit(df_ind)\n",
    "    \n",
    "    len_df = len(df)\n",
    "    \n",
    "    act_data = [ ['Activity', act_name],\n",
    "                 ['reference product',  act_name],\n",
    "                 ['code', act_code],\n",
    "                 ['location', 'CH'],\n",
    "                 ['amount', 1],\n",
    "                 ['unit', act_unit] ]\n",
    "    \n",
    "    df_act = pd.DataFrame( act_data, \n",
    "                           columns=list('AB'),\n",
    "                           index = np.arange(len_df,len_df+len(act_data)) )\n",
    "                          \n",
    "    df = df.append(df_act, sort=False)\n",
    "    \n",
    "    return df, df_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_exchanges_in_correct_columns(df, dict_with_values):\n",
    "    '''\n",
    "    Make sure that exchanges values are appended to df in the correct columns.\n",
    "    '''  \n",
    "    col_names = list(dict_with_values.keys()) # order of columns is determined by this list\n",
    "    col_excel_literal = [EXC_COLUMNS_DICT[m] for m in col_names]\n",
    "    \n",
    "    if dict_with_values != EXC_COLUMNS_DICT:\n",
    "        col_data  = [dict_with_values[m] for m in col_names]\n",
    "    else:\n",
    "        col_data = col_names\n",
    "    \n",
    "    df = df.append(pd.DataFrame([col_data], columns=col_excel_literal, index=[len(df)]), sort=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_exchanges_column_names(df):\n",
    "    '''\n",
    "    Add column names for exchanges\n",
    "    '''\n",
    "    df = df.append(pd.DataFrame(['Exchanges'], columns=['A'], index=[len(df)]), sort=False)\n",
    "    df = append_exchanges_in_correct_columns(df, EXC_COLUMNS_DICT)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_first_exchange(df, df_act):\n",
    "    '''\n",
    "    Append first exchange which is activity itself, the amount is always 1, \n",
    "    the database is always the one that is being currently created, type is `production`.\n",
    "    '''\n",
    "    df_act_dict = df_act.set_index('A').to_dict()['B']\n",
    "    \n",
    "    first_exc_data_dict = { 'name': df_act_dict['Activity'],\n",
    "                            'reference product': df_act_dict['reference product'],\n",
    "                            'location': df_act_dict['location'],\n",
    "                            'amount': 1,\n",
    "                            'unit': df_act_dict['unit'],\n",
    "                            'database': CONSUMPTION_DB_NAME,\n",
    "                            'type': 'production',\n",
    "                          }\n",
    "    \n",
    "    df = append_exchanges_in_correct_columns(df, first_exc_data_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pattern_correct(df_ind_j):\n",
    "    '''\n",
    "    Check that input activity info has correct pattern. \n",
    "    In case the pattern is not correct, move on to the next 5 columns and check their pattern.\n",
    "    This is needed because for some input activities some relevant values are missing, eg only 'On' value is present.\n",
    "    '''\n",
    "    list_ = list(df_ind_j.index)\n",
    "    pattern = ['On', 'Activity', 'DB Act', 'CFL Act', 'Amount Act']\n",
    "    check = [pattern[n] in list_[n] for n in range(N_COLUMNS_INPUT_ACTIVITY)]\n",
    "    if np.all(check): \n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_exchanges(df, df_ind, df_act):\n",
    "    '''\n",
    "    Add all exchanges (input activities) from the row df_ind to consumption database dataframe.\n",
    "    '''\n",
    "    # Add exchanges column names\n",
    "    df = append_exchanges_column_names(df)\n",
    "    \n",
    "    # Add first exchange that is the same as the activity itself, type of this exchange is production\n",
    "    df = append_first_exchange(df, df_act)\n",
    "    \n",
    "    # Add all exchanges\n",
    "    n_exchanges = (len(df_ind)-FIRST_ACT_IND) // N_COLUMNS_INPUT_ACTIVITY\n",
    "#     if n_exchanges != (len(df_ind) - FIRST_ACT_IND) / N_COLUMNS_INPUT_ACTIVITY:\n",
    "#         print('smth is not right with exchanges of Activity -> ' + str(df_ind['Translated name']))\n",
    "    \n",
    "    ConversionDem2FU = df_ind['ConversionDem2FU']\n",
    "    skip = 0\n",
    "    for j in range(1, n_exchanges+1):\n",
    "        \n",
    "        start = FIRST_ACT_IND + N_COLUMNS_INPUT_ACTIVITY*(j-1) + skip\n",
    "        end = start + N_COLUMNS_INPUT_ACTIVITY\n",
    "        df_ind_j = df_ind[start:end]\n",
    "        \n",
    "        #Check that df_ind_j contains <On 1, Activity 1, DB Act 1, CFL Act 1, Amount Act 1> pattern\n",
    "        flag = 1\n",
    "        while flag:\n",
    "            flag_pattern = is_pattern_correct(df_ind_j) \n",
    "            if flag_pattern == 1: # we don't need to skip if patter is correct\n",
    "                flag = 0\n",
    "            else:\n",
    "                skip += 1\n",
    "                start = FIRST_ACT_IND + N_COLUMNS_INPUT_ACTIVITY*(j-1) + skip\n",
    "                end = start + N_COLUMNS_INPUT_ACTIVITY\n",
    "                df_ind_j = df_ind[start:end]\n",
    "        \n",
    "        df = append_one_exchange(df, df_ind_j, ConversionDem2FU)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_act_dict(act_bw, input_act_amount):\n",
    "    '''\n",
    "    Create a dictionary with all info about input activities.\n",
    "    '''\n",
    "    \n",
    "    input_act_values_dict = {\n",
    "        'name': act_bw['name'], \n",
    "        'location': act_bw['location'], \n",
    "        'amount': input_act_amount, \n",
    "        'unit': act_bw['unit'], \n",
    "        'database': act_bw['database'], \n",
    "        # We do not expect type biosphere, but assign it via ACTIVITY_TYPE_DICT anyway \n",
    "        # to be sure that we don't encounter them.\n",
    "        'type': ACTIVITY_TYPE_DICT[act_bw['type']],\n",
    "    }\n",
    "    try:\n",
    "        input_act_values_dict['reference product'] = act_bw['reference product']\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    return input_act_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bw_get_activity_info_manually(input_act_str, db_name, input_act_amount):\n",
    "    # Extract the activity name\n",
    "    apostrophes = [(m.start(0), m.end(0)) for m in re.finditer(\"'\", input_act_str)]\n",
    "    if len(apostrophes) == 1:\n",
    "        ap_start = 0\n",
    "        ap_end = apostrophes[0][0]\n",
    "    else:\n",
    "        ap_start = apostrophes[0][1]\n",
    "        ap_end = apostrophes[1][0]\n",
    "    input_act_name = input_act_str[ ap_start:ap_end ]\n",
    "    input_act_unit_loc = input_act_str[ input_act_str.find(\"(\") : input_act_str.find(\")\")+1 ]\n",
    "    input_act_unit_loc_split = [ re.sub('[^-A-Za-z0-9-€-]', ' ' , el).rstrip().lstrip() \\\n",
    "                                 for el in input_act_unit_loc.split(',')]\n",
    "    input_act_unit = input_act_unit_loc_split[0]\n",
    "    input_act_location = input_act_unit_loc_split[1]\n",
    "\n",
    "    # Add comment when activity cannot be found\n",
    "    input_act_values_dict = {}\n",
    "    input_act_values_dict['name'] = input_act_name\n",
    "    input_act_values_dict['unit'] = input_act_unit\n",
    "    input_act_values_dict['location'] = input_act_location\n",
    "    input_act_values_dict['amount'] = input_act_amount\n",
    "    input_act_values_dict['database'] = db_name\n",
    "    input_act_values_dict['type'] = ACTIVITY_TYPE_DICT['process'] # TODO remove hardcoding\n",
    "    input_act_values_dict['comment'] = 'TODO could not find this activity'\n",
    "\n",
    "    return input_act_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def append_one_exchange(df, df_ind_j, ConversionDem2FU):\n",
    "    '''\n",
    "    Extract information about one input activity, eg name, unit, location, etc and append it to the dataframe df.\n",
    "    '''    \n",
    "    # Extract the activity number\n",
    "    k = int(''.join(c for c in df_ind_j.index[0] if c.isdigit()))\n",
    "    # Extract information about activity and save it\n",
    "    input_act_str = df_ind_j['DB Act ' + str(k)]\n",
    "    input_act_db_code = df_ind_j['Activity ' + str(k)]\n",
    "    \n",
    "    # Find this input activity in brightway databases\n",
    "    db_name = input_act_db_code.split(\"'\")[1]\n",
    "    code = input_act_db_code.split(\"'\")[3]\n",
    "    input_act_db_code_tuple = (db_name, code)\n",
    "    \n",
    "    # TODO remove HEIA for now\n",
    "    if 'heia' in db_name:\n",
    "        return df\n",
    "    \n",
    "    # Compute amount\n",
    "    input_act_amount = df_ind_j['On ' + str(k)] \\\n",
    "                     * df_ind_j['Amount Act ' + str(k)] \\\n",
    "                     * df_ind_j['CFL Act ' + str(k)] \\\n",
    "                     * ConversionDem2FU\n",
    "    \n",
    "    try:\n",
    "        # Find activity using bw functionality\n",
    "        act_bw = bw.get_activity(input_act_db_code_tuple)\n",
    "        input_act_values_dict = create_input_act_dict(act_bw, input_act_amount)\n",
    "    except:\n",
    "        # If bw.get_activity does not work for whichever reason, fill info manually\n",
    "        input_act_values_dict = bw_get_activity_info_manually(input_act_str, db_name, input_act_amount)\n",
    "        \n",
    "    # Add exchange to the dataframe with database in brightway format\n",
    "    df = append_exchanges_in_correct_columns(df, input_act_values_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to brightway database format -> main code\n",
    "calls all the functions used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Start brightway project that already contains databases\n",
    "project = 'GSA for ecoinvent'\n",
    "bw.projects.set_current(project)\n",
    "\n",
    "# Create dataframe that will be our consumption database after we add activities and exchanges from the raw file\n",
    "df_bw = create_df_bw(CONSUMPTION_DB_NAME)\n",
    "\n",
    "# Read data\n",
    "path = 'data/es8b01452_si_002.xlsx'\n",
    "sheet_name = 'Overview & LCA-Modeling'\n",
    "df_raw = pd.read_excel(path, sheet_name = sheet_name, header=2)\n",
    "\n",
    "# Add ON columns\n",
    "df = complete_columns(df_raw)\n",
    "\n",
    "act_indices = df_raw.index[df_raw['ConversionDem2FU'].notna()].tolist() # indices of all activities\n",
    "\n",
    "for ind in act_indices:\n",
    "    # For each row\n",
    "    df_ind = df_raw.iloc[ind]\n",
    "    df_ind = df_ind[df_ind.notna()]\n",
    "    # Add activity\n",
    "    df_bw, df_act = append_activity(df_bw, df_ind[:N_ACT_RELEVANT]) # only pass columns relevant to this function \n",
    "    # Add exchanges\n",
    "    df_bw = append_exchanges(df_bw, df_ind, df_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dataframe to excel file\n",
    "write_dir_name = 'write_files'\n",
    "if not os.path.exists(write_dir_name):\n",
    "    os.mkdir(write_dir_name)\n",
    "db_bw_path = write_dir_name + '/' + 'consumption_db.xlsx'\n",
    "df_bw.to_excel(db_bw_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ Part 2 ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import brightway2 as bw\n",
    "import string\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "# Local files\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_COLUMN = 'F'\n",
    "CONSUMPTION_DB_NAME = 'CH consumption 1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace names of old databases with the new ones in the consumption database excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_one_db(df, db_old_name, db_new_name):\n",
    "    '''\n",
    "    Replace database name with a new one (eg in case a newer version is available)\n",
    "    '''\n",
    "    df_updated = copy(df)\n",
    "    \n",
    "    where = np.where(df_updated[DB_COLUMN]==db_old_name)[0]\n",
    "    if where.shape[0] != 0:\n",
    "        df_updated[DB_COLUMN][where] = db_new_name\n",
    "        \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all_db(df):\n",
    "    '''\n",
    "    Update all databases in the consumption database\n",
    "    '''\n",
    "    db_old_list = ['Agribalyse 1.2', \n",
    "                   'ecoinvent 3.3 cutoff']\n",
    "    db_new_list = ['Agribalyse 1.3 - ecoinvent 3.6 cutoff',\n",
    "                  'ecoinvent 3.6 cutoff']\n",
    "    \n",
    "    assert len(db_old_list) == len(db_new_list)\n",
    "    \n",
    "    for i in range(len(db_old_list)):\n",
    "        df = replace_one_db(df, db_old_list[i], db_new_list[i])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "project = 'GSA for ecoinvent'\n",
    "bw.projects.set_current(project)\n",
    "\n",
    "# Read consumption database\n",
    "path = 'write_files/consumption_db.xlsx'\n",
    "df = pd.read_excel(path, header = None)\n",
    "df.columns = list(string.ascii_uppercase[:len(df.columns)])\n",
    "# \n",
    "# Replace\n",
    "df = update_all_db(df)\n",
    "path_new_db = 'write_files/consumption_db_updated.xlsx'\n",
    "df.to_excel(path_new_db, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import consumption database linked to older versions of other databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ecoinvent 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Chris -> please check migrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CONSUMPTION_DB_NAME in bw.databases:\n",
    "    del bw.databases[CONSUMPTION_DB_NAME]\n",
    "co = bw.ExcelImporter(path_new_db)\n",
    "co.apply_strategies()\n",
    "co.match_database('EXIOBASE 2.2', fields=('name','reference product', 'unit','location','categories'))\n",
    "co.match_database('ecoinvent 3.6 cutoff', fields=('name', 'reference product', 'unit','location','categories'))\n",
    "co.match_database('Agribalyse 1.3 - ecoinvent 3.6 cutoff', fields=('name','unit','location'))\n",
    "co.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a migration for two particular activities that can only be hardcoded\n",
    "ecoinvent36_change_names_data = {\n",
    "    'fields': ['name', ],\n",
    "    'data': [\n",
    "        (\n",
    "            ['steam production in chemical industry'], \n",
    "            {\n",
    "                'name': 'steam production, in chemical industry',\n",
    "                'reference product': 'steam, in chemical industry',\n",
    "                'unit': 'kilogram',\n",
    "                'multiplier': 1/2.75, # see comment on this activity in ecoinvent\n",
    "            }\n",
    "        ),\n",
    "        (\n",
    "            ['market for green bell pepper'],\n",
    "            {\n",
    "                'name': 'market for bell pepper',\n",
    "                'reference product': 'bell pepper',\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    "}\n",
    "\n",
    "bw.Migration(\"ecoinvent36-change-names\").write(\n",
    "    ecoinvent36_change_names_data,\n",
    "    description=\"Change names of some activities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a migration for rice production and specific locations\n",
    "# These locations have only non-basmati rice production\n",
    "ecoinvent36_rice_production_data = {\n",
    "    'fields': ['name', 'location'],\n",
    "    'data': [\n",
    "        (\n",
    "            ['rice production', 'US'],\n",
    "            {\n",
    "                'name': 'rice production, non-basmati',\n",
    "                'reference product': 'rice, non-basmati'\n",
    "            }\n",
    "        ),\n",
    "        (\n",
    "            ['rice production', 'CN'],\n",
    "            {\n",
    "                'name': 'rice production, non-basmati',\n",
    "                'reference product': 'rice, non-basmati'\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    "}\n",
    "\n",
    "bw.Migration(\"ecoinvent36-rice-production\").write(\n",
    "    ecoinvent36_rice_production_data,\n",
    "    description=\"Change names of some activities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.migrate('ecoinvent36-change-names')\n",
    "co.migrate(\"ecoinvent36-rice-production\")\n",
    "co.match_database('ecoinvent 3.6 cutoff', fields=('name','reference product', 'unit','location','categories'))\n",
    "co.statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the unlinked exchanges are not uniquely defined in ecoinvent 3.6 -> 1-to-multiple mapping. <br>\n",
    "For example 'rice production' is now divided into basmati and non-basmati rice. <br>\n",
    "Hence, we split them based on their shares in the production volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually choose which ecoinvent 3.6 exchanges should be taken for each unlinked exchange\n",
    "ei36 = bw.Database('ecoinvent 3.6 cutoff')\n",
    "mapping = [\n",
    "    {('market for rice', 'GLO'): \n",
    "        [act['code'] for act in ei36 if  'market for rice' in act['name'] \n",
    "                                     and act['location']=='GLO'\n",
    "                                     and 'seed' not in act['name']]},\n",
    "    \n",
    "    {('rice production', 'RoW'): \n",
    "        [act['code'] for act in ei36 if  'rice production' in act['name'] \n",
    "                                     and act['location']=='RoW'\n",
    "                                     and 'straw' not in act['reference product']]},\n",
    "    \n",
    "    {('rice production', 'IN'): \n",
    "        [act['code'] for act in ei36 if  'rice production' in act['name'] \n",
    "                                     and act['location']=='IN'\n",
    "                                     and 'straw' not in act['reference product']]},\n",
    "    \n",
    "    {('market for wheat grain', 'GLO'): \n",
    "        [act['code'] for act in ei36 if  'market for wheat grain' in act['name'] \n",
    "                                     and 'feed' not in act['name']]},\n",
    "    \n",
    "    {('market for maize grain', 'GLO'): \n",
    "        [act['code'] for act in ei36 if  'market for maize grain' in act['name'] \n",
    "                                     and 'feed' not in act['name']]},\n",
    "    \n",
    "    {('market for mandarin', 'GLO'): \n",
    "        [act['code'] for act in ei36 if 'market for mandarin' in act['name']]},\n",
    "    \n",
    "    {('market for soybean', 'GLO'): \n",
    "        [act['code'] for act in ei36 if 'market for soybean' in act['name'] \n",
    "                             and all([_ not in act['name'] for _ in ['meal','beverage','seed','feed','oil']] )]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei_name = 'ecoinvent 3.6 cutoff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = modify_exchanges(co, mapping, 'ecoinvent 3.6 cutoff')\n",
    "co.statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONSUMPTION_DB_NAME in bw.databases:\n",
    "    print(CONSUMPTION_DB_NAME + \" database already present!!! No import is needed\")\n",
    "else:\n",
    "    co.write_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------ Part 3 ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current('GSA for ecoinvent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = bw.Database('CH consumption 1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add consumption activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel file `heia2_totaldemands.xlsx` contains sums of all private households in Switzerland for all categories of the HBS. Please note that the units are basically the same as in the HBS (please refer to the SI-excel of Andi's ES&T-paper in order to translate the codenames). However, the attached vector is in \"per year\" instead of in \"per month\". Furthermore, there are a couple of demands that were computed by the model itself. The codenames for these computed/imputed categories start with \"mx\" and the units are as follows:\n",
    "* kWh per year for electricity\n",
    "* MJ per year for heating\n",
    "* cubic meters per year for water supply and wastewater collection\n",
    "* number of waste bags per year for refuse collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/heia2_totaldemands.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path, header=None)\n",
    "df.columns = ['code', 'amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    code = df.iloc[i]['code']\n",
    "    new_code = code\n",
    "    df.at[i,'code'] = new_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total inputs from Andi's model as swiss consumption activity\n",
    "try: co.get('ch_hh_consumption').delete()\n",
    "except: pass\n",
    "consumption = co.new_activity('ch_hh_consumption', name='ch hh consumption', location='CH', unit='unit')\n",
    "consumption.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add production exchange for the activity `consumption`\n",
    "consumption.new_exchange(input = (consumption['database'], consumption['code']),\n",
    "                         amount = 1,\n",
    "                         type = 'production').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codes = [act['code'] for act in co]\n",
    "\n",
    "unlinked_codes = []\n",
    "for i in range(len(df)):\n",
    "    code = df.loc[i]['code']\n",
    "    if code in codes:\n",
    "        consumption.new_exchange(input=(co.name, code), \n",
    "                                 amount=df.loc[i]['amount']/12, # divide by number of months\n",
    "                                 type = 'technosphere').save()\n",
    "    else:\n",
    "        unlinked_codes.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(consumption.exchanges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(consumption.exchanges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that the number of consumption exchanges is the same as the number of activities in the database, but is a lot less than what Andi provided in his total demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = {consumption: 1}\n",
    "method = ('IPCC 2013', 'climate change', 'GTP 100a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lca = bw.LCA(demand, method)\n",
    "lca.lci()\n",
    "lca.lcia()\n",
    "print(str(lca.score) + ' ' + bw.Method(method).metadata['unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
